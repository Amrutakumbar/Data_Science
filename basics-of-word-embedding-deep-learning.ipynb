{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMPORT THE LIBRARIES","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport array\nimport pandas as pd\nfrom keras.preprocessing.text import one_hot\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers.embeddings import Embedding","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:19:14.277794Z","iopub.execute_input":"2021-08-08T11:19:14.278356Z","iopub.status.idle":"2021-08-08T11:19:20.507668Z","shell.execute_reply.started":"2021-08-08T11:19:14.278254Z","shell.execute_reply":"2021-08-08T11:19:20.506499Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Load and define dataset","metadata":{}},{"cell_type":"code","source":"# define documents\ndocs = ['Well done!',  #1      \n'Good work',  #1\n'Great effort', #1\n'nice work', #1\n'Excellent!', \n'Weak', \n'Poor effort!',  #0\n'not good',  #0\n'poor work',\n'Could have done better.']\n# define class labels\nlabels = np.array([1,1,1,1,1,0,0,0,0,0])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:20:53.667742Z","iopub.execute_input":"2021-08-08T11:20:53.668096Z","iopub.status.idle":"2021-08-08T11:20:53.674417Z","shell.execute_reply.started":"2021-08-08T11:20:53.668068Z","shell.execute_reply":"2021-08-08T11:20:53.673350Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#1= postive words   , #0= negative words","metadata":{}},{"cell_type":"markdown","source":"Encoding the vocab(#unique words)","metadata":{}},{"cell_type":"code","source":"# integer encode the documents\nvocab_size = 50\nencoded_docs = [one_hot(d, vocab_size) for d in docs]  #https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/one_hot\nprint(encoded_docs)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:23:30.644339Z","iopub.execute_input":"2021-08-08T11:23:30.644710Z","iopub.status.idle":"2021-08-08T11:23:30.650232Z","shell.execute_reply.started":"2021-08-08T11:23:30.644681Z","shell.execute_reply":"2021-08-08T11:23:30.649091Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"[[36, 2], [21, 48], [15, 18], [10, 48], [20], [41], [18, 18], [49, 21], [18, 48], [18, 18, 2, 28]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Padding(#give input,it will return output)","metadata":{}},{"cell_type":"code","source":"# pad documents to a max length of 4 words\nmax_length = 4\npadded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\nprint(padded_docs)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:24:48.817881Z","iopub.execute_input":"2021-08-08T11:24:48.818257Z","iopub.status.idle":"2021-08-08T11:24:48.826639Z","shell.execute_reply.started":"2021-08-08T11:24:48.818226Z","shell.execute_reply":"2021-08-08T11:24:48.825444Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[[36  2  0  0]\n [21 48  0  0]\n [15 18  0  0]\n [10 48  0  0]\n [20  0  0  0]\n [41  0  0  0]\n [18 18  0  0]\n [49 21  0  0]\n [18 48  0  0]\n [18 18  2 28]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The Embedding has a vocabulary of 50 and an input length of 4. We will choose a small embedding space of 8 dimensions.\n\nThe model is a simple binary classification model. Importantly, the output from the Embedding layer will be 4 vectors of 8 dimensions each, one for each word. We flatten this to a one 32-element vector to pass on to the Dense output layer.\n\n","metadata":{}},{"cell_type":"markdown","source":"Define the model","metadata":{}},{"cell_type":"code","source":"# define the model\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 8, input_length=max_length))\nmodel.add(Flatten())\nmodel.add(Dense(1, activation='sigmoid'))\n# compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# summarize the model\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:26:18.887985Z","iopub.execute_input":"2021-08-08T11:26:18.888444Z","iopub.status.idle":"2021-08-08T11:26:18.926667Z","shell.execute_reply.started":"2021-08-08T11:26:18.888410Z","shell.execute_reply":"2021-08-08T11:26:18.925667Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 4, 8)              400       \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 433\nTrainable params: 433\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Fit the model And Get accuracy","metadata":{}},{"cell_type":"code","source":"0# fit the model\nmodel.fit(padded_docs, labels, epochs=50, verbose=0)\n# evaluate the model\nloss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\nprint('Accuracy: %f' % (accuracy*100))","metadata":{"execution":{"iopub.status.busy":"2021-08-08T11:27:01.127638Z","iopub.execute_input":"2021-08-08T11:27:01.127997Z","iopub.status.idle":"2021-08-08T11:27:02.209882Z","shell.execute_reply.started":"2021-08-08T11:27:01.127967Z","shell.execute_reply":"2021-08-08T11:27:02.208703Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Accuracy: 89.999998\n","output_type":"stream"}]}]}